# =============================================================================
# ENVIRONMENT CONFIGURATION TEMPLATE
# =============================================================================
# This file serves as a template for environment variables needed by the application.
# Copy this file to .env and fill in your actual values.
# IMPORTANT: Never commit .env files to version control! They contain secrets.
#
# In Go, we'll use the "viper" library to read these environment variables.
# Environment variables allow us to configure our application without changing code.
# =============================================================================

# -----------------------------------------------------------------------------
# ENVIRONMENT SETTINGS
# -----------------------------------------------------------------------------
# ENVIRONMENT determines which configuration set to use (development, staging, production)
# This helps us have different settings for different deployment environments
ENVIRONMENT=development

# VERSION is the application version - useful for tracking deployments
# In production, this might come from your CI/CD pipeline
VERSION=1.0.0

# -----------------------------------------------------------------------------
# SERVER CONFIGURATION
# -----------------------------------------------------------------------------
# These settings control how our HTTP servers listen for requests

# SERVICE_NAME helps identify which service is running (useful in logs and metrics)
SERVICE_NAME=file-storage-service

# HTTP_PORT is the port number where the server listens
# In Go, servers listen on a specific port (like 8080) to receive HTTP requests
HTTP_PORT=8080

# SHUTDOWN_TIMEOUT is how long to wait for graceful shutdown
# When stopping the server, we wait this long for ongoing requests to finish
SHUTDOWN_TIMEOUT=30s

# READ_TIMEOUT is the maximum duration for reading the entire request
# Prevents slow clients from holding connections open indefinitely
READ_TIMEOUT=15s

# WRITE_TIMEOUT is the maximum duration before timing out writes of the response
# Prevents the server from hanging when writing responses
WRITE_TIMEOUT=15s

# -----------------------------------------------------------------------------
# MONGODB DATABASE CONFIGURATION
# -----------------------------------------------------------------------------
# MongoDB is our NoSQL database for storing file metadata, user information, etc.

# MONGO_ROOT_USER and MONGO_ROOT_PASSWORD are admin credentials for MongoDB
# These are used to create the initial admin user in MongoDB
MONGO_ROOT_USER=admin
MONGO_ROOT_PASSWORD=changeme_secure_password

# MONGO_URI is the connection string to MongoDB
# Format: mongodb://username:password@host:port
# In Docker Compose, "mongodb" is the service name that acts as hostname
MONGO_URI=mongodb://admin:changeme_secure_password@mongodb:27017

# MONGO_DATABASE is the name of the database we'll use
# MongoDB can have multiple databases; this is our main one
MONGO_DATABASE=file_storage

# Connection pool settings - these control how many database connections we maintain
# MONGO_MAX_POOL_SIZE: Maximum number of connections in the pool
# Too many connections waste resources; too few cause bottlenecks
MONGO_MAX_POOL_SIZE=100

# MONGO_MIN_POOL_SIZE: Minimum number of connections to keep open
# Keeping some connections open avoids the overhead of creating new ones
MONGO_MIN_POOL_SIZE=10

# MONGO_MAX_CONN_IDLE_TIME: How long a connection can be idle before closing
# This prevents keeping unused connections open indefinitely
MONGO_MAX_CONN_IDLE_TIME=30s

# MONGO_CONNECT_TIMEOUT: Maximum time to wait when connecting to MongoDB
# If MongoDB doesn't respond in this time, the connection attempt fails
MONGO_CONNECT_TIMEOUT=10s

# -----------------------------------------------------------------------------
# RABBITMQ MESSAGE QUEUE CONFIGURATION
# -----------------------------------------------------------------------------
# RabbitMQ is our message broker for asynchronous, event-driven communication
# between microservices. It implements the AMQP (Advanced Message Queuing Protocol)

# RABBITMQ_USER and RABBITMQ_PASSWORD are credentials for RabbitMQ
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest

# RABBITMQ_URL is the connection string to RabbitMQ
# Format: amqp://username:password@host:port/vhost
# The "/" at the end is the virtual host (default vhost in RabbitMQ)
RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/

# RABBITMQ_EXCHANGE is the name of the exchange where we publish messages
# In RabbitMQ, exchanges route messages to queues based on routing keys
RABBITMQ_EXCHANGE=file-storage-exchange

# RABBITMQ_PREFETCH_COUNT controls how many messages a worker fetches at once
# This is important for load balancing among multiple worker instances
# Lower values = more even distribution, higher values = better throughput
RABBITMQ_PREFETCH_COUNT=10

# RABBITMQ_RECONNECT_DELAY: How long to wait before reconnecting if connection drops
# Network issues happen; this ensures we automatically reconnect
RABBITMQ_RECONNECT_DELAY=5s

# -----------------------------------------------------------------------------
# AWS S3 / MINIO STORAGE CONFIGURATION
# -----------------------------------------------------------------------------
# S3 (Simple Storage Service) stores our actual file content
# MinIO is an S3-compatible storage server we use for local development

# AWS_REGION is the AWS region where your S3 bucket is located
# Not needed for MinIO in development, but required for production AWS S3
AWS_REGION=us-east-1

# S3_ENDPOINT is the URL of the S3 service
# For local development with MinIO: http://minio:9000
# For production AWS S3: leave empty or set to https://s3.amazonaws.com
S3_ENDPOINT=http://minio:9000

# S3_BUCKET is the name of the bucket where files are stored
# Buckets are like top-level folders in S3
S3_BUCKET=file-storage

# S3_USE_SSL determines whether to use HTTPS for S3 connections
# false for local MinIO, true for production AWS S3
S3_USE_SSL=false

# MinIO specific settings (for local development only)
# These are the default MinIO credentials
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin

# AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY are credentials for AWS/MinIO
# For AWS: Get these from IAM (Identity and Access Management)
# For MinIO: Use the root user credentials
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin

# PRESIGN_URL_EXPIRY: How long pre-signed URLs remain valid
# Pre-signed URLs allow clients to upload/download directly to/from S3
# 15m = 15 minutes (enough time to complete an upload without security risk)
PRESIGN_URL_EXPIRY=15m

# CHUNK_SIZE: Size of each chunk for multipart uploads (in bytes)
# 5MB is the minimum chunk size for S3 multipart uploads
# 5242880 bytes = 5 * 1024 * 1024 = 5 MB
CHUNK_SIZE=5242880

# MAX_FILE_SIZE: Maximum allowed file size (in bytes)
# 5GB = 5 * 1024 * 1024 * 1024 = 5368709120 bytes
MAX_FILE_SIZE=5368709120

# -----------------------------------------------------------------------------
# REDIS CACHE CONFIGURATION
# -----------------------------------------------------------------------------
# Redis is an in-memory data store we use for caching and rate limiting
# It's extremely fast because data is stored in RAM

# REDIS_HOST and REDIS_PORT specify where Redis is running
REDIS_HOST=redis
REDIS_PORT=6379

# REDIS_PASSWORD for authentication
# In production, always use a strong password for Redis
REDIS_PASSWORD=changeme_redis_password

# REDIS_DB: Redis database number (0-15)
# Redis supports multiple databases (numbered 0-15)
# We use database 0 for this application
REDIS_DB=0

# REDIS_MAX_RETRIES: How many times to retry failed Redis operations
REDIS_MAX_RETRIES=3

# REDIS_POOL_SIZE: Maximum number of socket connections
# Higher values allow more concurrent Redis operations
REDIS_POOL_SIZE=100

# -----------------------------------------------------------------------------
# JWT (JSON WEB TOKEN) CONFIGURATION
# -----------------------------------------------------------------------------
# JWT is used for stateless authentication - the token contains user information
# and is cryptographically signed to prevent tampering

# JWT_SECRET is the secret key used to sign JWT tokens
# CRITICAL: Use a strong, random string in production (at least 32 characters)
# This secret must be kept confidential! If leaked, tokens can be forged
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production-min-32-chars

# JWT_EXPIRY: How long access tokens remain valid
# 24h = 24 hours. Shorter is more secure, but users have to login more often
# Common values: 15m (very secure), 1h (balanced), 24h (convenient)
JWT_EXPIRY=24h

# JWT_REFRESH_EXPIRY: How long refresh tokens remain valid
# Refresh tokens are used to get new access tokens without re-logging in
# 168h = 7 days = 1 week
JWT_REFRESH_EXPIRY=168h

# JWT_ISSUER: Identifies who issued the token
# Useful when multiple services issue tokens
JWT_ISSUER=file-storage-service

# -----------------------------------------------------------------------------
# RATE LIMITING CONFIGURATION
# -----------------------------------------------------------------------------
# Rate limiting prevents abuse by limiting how many requests a user can make
# We use the "token bucket" algorithm implemented in Redis

# RATE_LIMIT_ENABLED: Turn rate limiting on/off
RATE_LIMIT_ENABLED=true

# RATE_LIMIT_REQUESTS_PER_MIN: How many requests per minute are allowed
# For free users: 60 requests/minute = 1 request per second average
RATE_LIMIT_REQUESTS_PER_MIN=60

# RATE_LIMIT_BURST_SIZE: Maximum tokens in the bucket
# Allows short bursts of traffic beyond the rate limit
# E.g., if set to 10, users can make 10 requests instantly, then wait for refill
RATE_LIMIT_BURST_SIZE=10

# -----------------------------------------------------------------------------
# OBSERVABILITY - LOGGING, METRICS, AND TRACING
# -----------------------------------------------------------------------------
# These tools help us monitor and debug our application in production

# LOG_LEVEL controls how much logging output we see
# Options: debug (most verbose), info, warn, error, fatal (least verbose)
# Use "debug" in development, "info" or "warn" in production
LOG_LEVEL=debug

# METRICS_ENABLED: Enable Prometheus metrics collection
# Metrics help us understand system performance (requests/sec, response time, etc.)
METRICS_ENABLED=true

# TRACING_ENABLED: Enable distributed tracing with Jaeger
# Tracing shows how requests flow through our microservices
# Invaluable for debugging issues in distributed systems
TRACING_ENABLED=true

# JAEGER_ENDPOINT: Where to send tracing data
# Jaeger collects and visualizes traces across microservices
JAEGER_ENDPOINT=http://jaeger:4318/v1/traces

# -----------------------------------------------------------------------------
# GRAFANA MONITORING DASHBOARD
# -----------------------------------------------------------------------------
# Grafana provides beautiful dashboards for visualizing metrics

# GRAFANA_ADMIN_USER and GRAFANA_ADMIN_PASSWORD
# Default credentials to access Grafana web interface
# Change these in production!
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=admin

# -----------------------------------------------------------------------------
# WORKER SERVICE CONFIGURATION
# -----------------------------------------------------------------------------
# Workers process background jobs (thumbnails, compression, etc.)

# WORKER_CONCURRENCY: How many jobs to process simultaneously
# Higher = faster processing but more resource usage
# Set based on your server's CPU cores (typically 2x CPU cores)
WORKER_CONCURRENCY=10

# -----------------------------------------------------------------------------
# NOTIFICATION SERVICE CONFIGURATION
# -----------------------------------------------------------------------------
# Settings for sending email notifications

# SMTP settings for sending emails
# SMTP (Simple Mail Transfer Protocol) is used to send emails
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-specific-password

# EMAIL_FROM: The email address that appears in the "From" field
EMAIL_FROM=noreply@file-storage.com

# SENDGRID_API_KEY: Alternative to SMTP, using SendGrid service
# SendGrid is a popular email delivery service with good deliverability
# Comment this out if using SMTP instead
# SENDGRID_API_KEY=your-sendgrid-api-key

# -----------------------------------------------------------------------------
# SECURITY CONFIGURATION
# -----------------------------------------------------------------------------

# CORS_ALLOWED_ORIGINS: Which websites can make requests to our API
# CORS (Cross-Origin Resource Sharing) is a security feature
# In development: allow all (*), in production: list specific domains
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# BCRYPT_COST: Computational cost for password hashing
# Higher = more secure but slower (range: 4-31)
# 12 is a good balance between security and performance
BCRYPT_COST=12

# -----------------------------------------------------------------------------
# FILE PROCESSING CONFIGURATION
# -----------------------------------------------------------------------------

# THUMBNAIL_SIZES: Comma-separated list of thumbnail widths to generate
# When an image is uploaded, we create thumbnails in these sizes
THUMBNAIL_SIZES=150,300,600

# COMPRESSION_ENABLED: Enable file compression for documents
COMPRESSION_ENABLED=true

# VIRUS_SCAN_ENABLED: Enable virus scanning for uploaded files
# Requires ClamAV to be installed in the processing-service container
VIRUS_SCAN_ENABLED=false

# -----------------------------------------------------------------------------
# SERVICE URLS (for inter-service communication)
# -----------------------------------------------------------------------------
# In Docker Compose, services can reach each other using service names as hostnames

# These URLs are used by the API Gateway to route requests to backend services
AUTH_SERVICE_URL=http://auth-service:8081
FILE_SERVICE_URL=http://file-service:8082
METADATA_SERVICE_URL=http://metadata-service:8083
PROCESSING_SERVICE_URL=http://processing-service:8084
VERSIONING_SERVICE_URL=http://versioning-service:8085
NOTIFICATION_SERVICE_URL=http://notification-service:8086

# =============================================================================
# USAGE INSTRUCTIONS
# =============================================================================
# 1. Copy this file: cp .env.example .env
# 2. Edit .env and replace all "changeme" values with secure passwords
# 3. Update AWS credentials if using real AWS S3
# 4. Adjust rate limits and worker concurrency based on your needs
# 5. Never commit .env to version control!
# =============================================================================
